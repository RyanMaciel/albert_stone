<html>
  <head>
    <link rel="stylesheet" href="./styles.css"/>
  </head>
  <body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-start">
        <a class="navbar-item" href="./index.html">Home</a>
        <a class="navbar-item" href="">Map</a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            Case Studies
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="./uofr/UofRMoveEssay.html">University of Rochester Move</a>
            <a class="navbar-item" href="./vet_memorial/VeteransmemorialBridgeEssay.html">Veteran's Memorial Bridge Construction</a>
          </div>
        </div>
        
        <a class="navbar-item" href="./SpatialHistoryAboutEssay.html">About</a>
        <a class="navbar-item" href="./Methodology.html">Methodology</a>
      </div>
    </nav>
    <div class="column is-half is-offset-one-quarter has-text-left">
      <h1 class="title">Methodology</h1>
      <p>The goal of this project is to take Albert R. Stone Negative Collection images and metadata from the RMSC online catalog and display them spatially. The work to accomplish this is divided into three steps: get the data from the catalog, label the images with location data, and display the augmented data on an interactive map. Since the collection is large, containing around fourteen thousand labeled images, completing these steps with any sort of efficiency was a major challenge. I heavily relied on several pieces of software that I wrote to help automate the processes.
        </p>
      <p>The first step, getting the images and metadata from the catalog, posed a significant challenge. Before starting, I got in touch with the RMSC collections staff to ask them about working with the data. They informed me that the best and perhaps only way to interact with the data was through the online catalog system. While this system works wonderfully for users searching for small subsets of images, getting the entire collection is very difficult. Collecting a single image and associated metadata by hand would entail clicking on an entry from a search result page, copying and saving the text metadata that opens in a new page, clicking on the image itself, and getting the image url by right clicking. One would have to do this nearly fourteen thousand times to collect the entire dataset.
        </p>
      <p>In order to make this process feasible for the project, I wrote a program called a web scraper. This is a program that interacts with a website in the same way a user might, using typical user interface interactions like clicking and scrolling to collect data. The web scraper was built specifically for navigating the RMSC catalog and downloading image data as described previously. This part of the project was perhaps the most challenging and took considerable effort, as there are many subtleties to how web scrapers work. They need to be designed not only to know what to do and where to go to get data, but also to handle missing data, website errors, unexpected website layouts and more. And while a web scraper can get data much faster than a human can, they still take considerable time to run. This is because requesting too much data from a website too fast can sometimes overwhelm it, and is generally considered an abuse of the website’s terms of service. Thus, I was very careful to make the software run much slower than it was capable of. I ran the software overnight for many nights to build up the dataset.
        </p>
      <p>The next step was to label the images with location data. Fortunately, the metadata attached to many images in the collection contained addresses, place names and other location-associated information in the “Description” field. In order to display images on a map, I needed to associate images with location information, and location information with latitude and longitude coordinates. This task needed to be done primarily by hand, but I built some software that I called a “loader” to assist me. This software gathers all of the image data from each different run of the web scraper (the data had to be split up because it would have taken too long to collect all the data at once.) Then, it prompts the user to search for keywords, the idea being that there are certain words and phrases—such as “street” or “nearby”—which indicate location data. After the search is performed, the software shows the user a preview of each matching image along with its metadata. The user is then prompted to enter one or more place names to label the image. The responses are saved as a text file of location names. The user must then edit this file with matching coordinates. The coordinates were found primarily by searching addresses with Google Maps, or placing images based on my personal familiarity with the location depicted. While this process is tedious and very specific to the collection itself, there is certainly opportunity to build a more straightforward system that might involve crowdsourced geolocation initiatives.
        </p>
      <p>The last step was to display the location-augmented data on an interactive map. Developing the user interface for this part of the project was based on my own previous work in user interface design, as well as many iterations of trying different concepts. Ultimately, this led to the interactive, searchable, and filterable map currently on the “Map” page of this website. This interactive element uses an open-source mapping software called Leaflet and underlying map image tiles from MapBox. Its interface takes inspiration from location-based search maps innovated by tech companies such as Airbnb and Zillow.
        </p>
      <p>This website and the project overall is still in progress. There are many images which have not been annotated with locations and there is definitely some room for improvement in the interface. However, splitting the presentation of the original catalog into the more free-form, spatially oriented interactive map and more formal essay-based case-studies provides new possibilities in how this important collection might be used. Distributing the images spatially gives more room for the incredible historical data in the collection to shine through and can augment the experiences of those who inhabit the same spaces in Rochester, New York 100 years later. I hope that this new way of visualizing and exploring the collection can open new lines of inquiry and help expose more to the rich and varied histories it contains.
        </p>
    </div>
  </body>
</html>>